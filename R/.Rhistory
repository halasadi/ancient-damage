gp=gpar(fill="green",
lwd=1))
}else{
grid.polygon(x, y,
default.unit="native",
id=id,
gp=gpar(col="green",
lwd=10))
}
grid.newpage()
pushViewport(viewport(x=0.5,y=0.5,width=1, height=1,
clip=TRUE))
grid.rect(gp=gpar(col="grey"))
x <- c(0, 0, 1, 1, 0.15, 0.15, 0.5, 0.5, 0.15, 0.15)
y <- c(0,1,1,0.85,0.85,0.575,0.575,0.425,0.425,0)
#x <- 0.1*x
#y <- 0.1*y
id <- rep(1,10)
fill_symbol <- TRUE
if(fill_symbol){
grid.polygon(x, y,
default.unit="native",
id=id,
gp=gpar(fill="green",
lwd=1))
}else{
grid.polygon(x, y,
default.unit="native",
id=id,
gp=gpar(col="green",
lwd=10))
}
source('~/Documents/Logolas/Fletter.R')
source('~/Documents/Logolas/Eletter.R')
source('~/Documents/Logolas/Fletter.R')
grid.newpage()
pushViewport(viewport(x=0.5,y=0.5,width=1, height=1,
clip=TRUE))
grid.rect(gp=gpar(col="grey"))
x <- c(0, 0, 0.25, 0.25, 0.75, 0.75, 1, 0, 0.75, 0.75, 0.25, 0)
y <- c(0, 1, 1, 0.6, 0.6, 1, 1, 0, 0, 0.4, 0.4, 0)
#x <- 0.1*x
#y <- 0.1*y
id <- rep(1,10)
fill_symbol <- TRUE
if(fill_symbol){
grid.polygon(x, y,
default.unit="native",
id=id,
gp=gpar(fill="green",
lwd=1))
}else{
grid.polygon(x, y,
default.unit="native",
id=id,
gp=gpar(col="green",
lwd=10))
}
grid.newpage()
pushViewport(viewport(x=0.5,y=0.5,width=1, height=1,
clip=TRUE))
grid.rect(gp=gpar(col="grey"))
x <- c(0, 0, 0.25, 0.25, 0.75, 0.75, 1, 0, 0.75, 0.75, 0.25, 0)
y <- c(0, 1, 1, 0.6, 0.6, 1, 1, 0, 0, 0.4, 0.4, 0)
#x <- 0.1*x
#y <- 0.1*y
id <- rep(1,12)
fill_symbol <- TRUE
if(fill_symbol){
grid.polygon(x, y,
default.unit="native",
id=id,
gp=gpar(fill="green",
lwd=1))
}else{
grid.polygon(x, y,
default.unit="native",
id=id,
gp=gpar(col="green",
lwd=10))
}
grid.newpage()
pushViewport(viewport(x=0.5,y=0.5,width=1, height=1,
clip=TRUE))
grid.rect(gp=gpar(col="grey"))
x <- c(0, 0, 0.25, 0.25, 0.75, 0.75, 1, 1, 0.75, 0.75, 0.25, 0)
y <- c(0, 1, 1, 0.6, 0.6, 1, 1, 0, 0, 0.4, 0.4, 0)
#x <- 0.1*x
#y <- 0.1*y
id <- rep(1,12)
fill_symbol <- TRUE
if(fill_symbol){
grid.polygon(x, y,
default.unit="native",
id=id,
gp=gpar(fill="green",
lwd=1))
}else{
grid.polygon(x, y,
default.unit="native",
id=id,
gp=gpar(col="green",
lwd=10))
}
source('~/Documents/Logolas/Hletter.R')
source('~/Documents/Logolas/Hletter.R')
source('~/.active-rstudio-document')
source('~/Documents/Logolas/Iletter.R')
source('~/Documents/Logolas/Jletter.R')
source('~/Documents/Logolas/Jletter.R')
source('~/Documents/Logolas/Jletter.R')
source('~/Documents/Logolas/Jletter.R')
source('~/Documents/Logolas/Kletter.R')
source('~/Documents/Logolas/Kletter.R')
source('~/Documents/Logolas/Kletter.R')
source('~/Documents/Logolas/Kletter.R')
source('~/Documents/Logolas/Kletter.R')
source('~/Documents/Logolas/Kletter.R')
source('~/Documents/Logolas/Lletter.R')
source('~/Documents/Logolas/Mletter.R')
source('~/Documents/Logolas/Mletter.R')
source('~/Documents/Logolas/Mletter.R')
source('~/Documents/Logolas/Mletter.R')
source('~/Documents/Logolas/Mletter.R')
source('~/Documents/Logolas/Nletter.R')
source('~/Documents/Logolas/Nletter.R')
source('~/Documents/Logolas/Nletter.R')
source('~/Documents/Logolas/Nletter.R')
source('~/Documents/Logolas/Nletter.R')
source('~/Documents/Logolas/Nletter.R')
grid.newpage()
pushViewport(viewport(x=0.5,y=0.5,width=1, height=1,
clip=TRUE))
grid.rect(gp=gpar(col="grey"))
grid.circle(x=0.5, y=0.5, r=0.5, gp=gpar(fill="green"))
grid.circle(x=0.5, y=0.5, r=0.3, gp=gpar(fill="white"))
source('~/Documents/Logolas/Tletter.R')
source('~/Documents/Logolas/Vletter.R')
source('~/Documents/Logolas/Vletter.R')
source('~/Documents/Logolas/Vletter.R')
source('~/Documents/Logolas/Vletter.R')
source('~/Documents/Logolas/Wletter.R')
source('~/Documents/Logolas/Wletter.R')
source('~/Documents/Logolas/Wletter.R')
source('~/Documents/Logolas/Wletter.R')
source('~/Documents/Logolas/Wletter.R')
source('~/Documents/Logolas/Wletter.R')
source('~/Documents/Logolas/Wletter.R')
source('~/Documents/Logolas/Wletter.R')
source('~/Documents/Logolas/Wletter.R')
source('~/Documents/Logolas/Wletter.R')
source('~/Documents/Logolas/Xletter.R')
source('~/Documents/Logolas/Xletter.R')
source('~/Documents/Logolas/Xletter.R')
source('~/Documents/Logolas/Xletter.R')
source('~/Documents/Logolas/Yletter.R')
source('~/Documents/Logolas/Yletter.R')
source('~/Documents/Logolas/R/makemylogo.R')
source('~/Documents/Logolas/R/lambdaletter.R')
source('~/Documents/Logolas/R/lambdaletter.R')
source('~/Documents/Logolas/R/lambdaletter.R')
source('~/Documents/Logolas/R/lambdaletter.R')
makemylogo("AC>EF/lambda/W23", addlogos="lambda", addlogos_text="lambda")
source('~/Documents/Logolas/R/makemylogo.R')
makemylogo("Q-BIO.QM;A,DD>R::C,123456789:D0O", plot=TRUE)
library(Logolas)
source('~/Documents/Logolas/R/makemylogo.R')
source('~/Documents/Logolas/R/makemylogo.R')
makemylogo("Q-BIO.QM;A,DD>R::C,123456789:D0O", plot=TRUE)
library(devtools)
install_github("kkdey/CountClust")
library(devtools)
install_github("kkdey/CountClust")
install_github("kkdey/CountClust")
install_github("kkdey/CountClust")
install_github("kkdey/CountClust")
library(CountClust)
library(CountClust)
library(CountClust)
source('~/Documents/sequence_clustering/src/cluster_seq_mix.R')
theta_mat_1 <- matrix(0.15, 20,20);
theta_mat_2 <- matrix(0.5, 20, 20);
theta_mat_3 <- matrix(0.85, 20, 20);
theta <- rbind(cbind(theta_mat_2, theta_mat_1), cbind(theta_mat_3, theta_mat_2))
library(fields)
image.plot(theta)
data <- apply(theta, c(1,2), function(x) rbinom(1, 1, x))
image.plot(data)
dim(data)
library(autoencoder)
nl=3 ## number of layers (default is 3: input, hidden, output)
unit.type = "logistic"
N.hidden = 100
max.iterations = 1000
lambda = 0.0002 ## weight decay parameter
beta = 6 ## weight of sparsity penalty term
rho = 0.01
epsilon <- 0.001
autoencoder.object <- autoencode(X.train=data,nl=nl,N.hidden=N.hidden,
unit.type=unit.type,lambda=lambda,beta=beta,rho=rho,epsilon=epsilon,
optim.method="BFGS",max.iterations=max.iterations,
rescale.flag=TRUE,rescaling.offset=0.001)
library(autoencoder)
nl=3 ## number of layers (default is 3: input, hidden, output)
unit.type = "logistic"
N.hidden = 10
max.iterations = 500
lambda = 0.002 ## weight decay parameter
beta = 6 ## weight of sparsity penalty term
rho = 0.01
epsilon <- 0.01
autoencoder.object <- autoencode(X.train=data,nl=nl,N.hidden=N.hidden,
unit.type=unit.type,lambda=lambda,beta=beta,rho=rho,epsilon=epsilon,
optim.method="BFGS",max.iterations=max.iterations,
rescale.flag=TRUE,rescaling.offset=0.001)
autoencoder.object
autoencoder.object$W[[1]]
plot(autoencoder.object$W[[1]])
plot(autoencoder.object$W[[2]])
dim(autoencoder.object$W[[2]])
proj <- autoencoder.object$W[[2]] %*% autoencoder.object$W[[1]]
dim(proj)
image.plot(proj)
X.output <- predict(autoencoder.object, X.input=data,
hidden.output=FALSE)$X.output
dim(X.output)
image.plot(X.output)
X.output <- predict(autoencoder.object, X.input=data,
hidden.output=TRUE)$X.output
image.plot(X.output)
X.output <- predict(autoencoder.object, X.input=data,
hidden.output=FALSE)$X.output
X.output
library(autoencoder)
nl=3 ## number of layers (default is 3: input, hidden, output)
unit.type = "logistic"
N.hidden = 4
max.iterations = 500
lambda = 0.002 ## weight decay parameter
beta = 6 ## weight of sparsity penalty term
rho = 0.01
epsilon <- 0.01
autoencoder.object <- autoencode(X.train=data,nl=nl,N.hidden=N.hidden,
unit.type=unit.type,lambda=lambda,beta=beta,rho=rho,epsilon=epsilon,
optim.method="BFGS",max.iterations=max.iterations,
rescale.flag=TRUE,rescaling.offset=0.001)
plot(autoencoder.object$W[[1]])
plot(autoencoder.object$W[[2]])
X.output <- predict(autoencoder.object, X.input=data,
hidden.output=FALSE)$X.output
image.plot(X.output)
library(autoencoder)
nl=3 ## number of layers (default is 3: input, hidden, output)
unit.type = "logistic"
N.hidden = 4
max.iterations = 500
lambda = 0.002 ## weight decay parameter
beta = 6 ## weight of sparsity penalty term
rho = 0.01
epsilon <- 0.01
autoencoder.object <- autoencode(X.train=data,nl=nl,N.hidden=N.hidden,
unit.type=unit.type,lambda=lambda,beta=beta,rho=rho,epsilon=epsilon,
optim.method="BFGS",max.iterations=max.iterations,
rescale.flag=TRUE,rescaling.offset=0.001)
plot(autoencoder.object$W[[1]])
plot(autoencoder.object$W[[2]])
X.output <- predict(autoencoder.object, X.input=data,
hidden.output=FALSE)$X.output
image.plot(X.output)
library(autoencoder)
nl=3 ## number of layers (default is 3: input, hidden, output)
unit.type = "logistic"
N.hidden = 4
max.iterations = 2000
lambda = 0.002 ## weight decay parameter
beta = 6 ## weight of sparsity penalty term
rho = 0.01
epsilon <- 0.01
autoencoder.object <- autoencode(X.train=data,nl=nl,N.hidden=N.hidden,
unit.type=unit.type,lambda=lambda,beta=beta,rho=rho,epsilon=epsilon,
optim.method="BFGS",max.iterations=max.iterations,
rescale.flag=TRUE,rescaling.offset=0.001)
plot(autoencoder.object$W[[1]])
plot(autoencoder.object$W[[2]])
X.output <- predict(autoencoder.object, X.input=data,
hidden.output=FALSE)$X.output
image.plot(X.output)
library(autoencoder)
nl=3 ## number of layers (default is 3: input, hidden, output)
unit.type = "logistic"
N.hidden = 4
max.iterations = 5000
lambda = 0.002 ## weight decay parameter
beta = 6 ## weight of sparsity penalty term
rho = 0.01
epsilon <- 0.01
autoencoder.object <- autoencode(X.train=data,nl=nl,N.hidden=N.hidden,
unit.type=unit.type,lambda=lambda,beta=beta,rho=rho,epsilon=epsilon,
optim.method="BFGS",max.iterations=max.iterations,
rescale.flag=TRUE,rescaling.offset=0.001)
plot(autoencoder.object$W[[1]])
plot(autoencoder.object$W[[2]])
X.output <- predict(autoencoder.object, X.input=data,
hidden.output=FALSE)$X.output
image.plot(X.output)
library(autoencoder)
nl=3 ## number of layers (default is 3: input, hidden, output)
unit.type = "logistic"
N.hidden = 2
max.iterations = 5000
lambda = 0.002 ## weight decay parameter
beta = 6 ## weight of sparsity penalty term
rho = 0.01
epsilon <- 0.01
autoencoder.object <- autoencode(X.train=data,nl=nl,N.hidden=N.hidden,
unit.type=unit.type,lambda=lambda,beta=beta,rho=rho,epsilon=epsilon,
optim.method="BFGS",max.iterations=max.iterations,
rescale.flag=TRUE,rescaling.offset=0.001)
plot(autoencoder.object$W[[1]])
plot(autoencoder.object$W[[2]])
X.output <- predict(autoencoder.object, X.input=data,
hidden.output=FALSE)$X.output
image.plot(X.output)
data
dim(data)
plot(autoencoder.object$W[[1]])
plot(autoencoder.object$W[[2]])
image.plot(autoencoder.object$W[[2]] %*% autoencoder.object$W[[1]])
cluster1 <- c(rep(0.001, 100), rep(0.02, 400,), rep(0.001, 200))
sum(cluster1)
cluster1 <- c(rep(0.001, 400), rep(0.002, 200,), rep(0.001, 400))
sum(cluster1)
cluster1 <- c(rep(0.001, 400), rep(0.002, 200), rep(0.001, 400))
sum(cluster1)
cluster1 <- c(rep(0.001, 300), rep(0.002, 200), rep(0.001, 300))
sum(cluster1)
plot(cluster2, type="l")
cluster1 <- c(rep(0.001, 300), rep(0.002, 200), rep(0.001, 300))
cluster2 <- c(rep(0.001, 500), rep(0.002, 200), rep(0.001, 100))
cluster3 <- c(rep(0.001, 100), rep(0.002, 200), rep(0.001, 500))
plot(cluster1, type="l")
plot(cluster2, type="l")
plot(cluster3, type="l")
omega <- cbind(seq(0,0.4, length.out=100), seq(0.5, 0.2, length.out=100),
1 - seq(0,0.4, length.out=100) - seq(0.5, 0.2, length.out=100))
dim(omega)
rowSums(omega)
cluster_theta <- cbind(cluster1, cluster2, cluster3);
dim(cluster_theta)
prob_mat <- omega%*%t(cluster_theta)
dim(prob_mat)
rmultinom(100, prob=prob_mat[n,])
rmultinom(1, size=100, prob=prob_mat[n,])
rmultinom(1, n=100, prob=prob_mat[n,])
n <- 1
rmultinom(1, size=100, prob=prob_mat[n,])
counts[n,] <-  sum(rmultinom(1, size=100, prob=prob_mat[n,]))
sum(rmultinom(1, size=100, prob=prob_mat[n,]))
counts <- matrix(0, dim(prob_mat)[1], dim(prob_mat)[2])
for(n in 1:dim(omega)[1]){
counts[n,] <-  rmultinom(1, size=100, prob=prob_mat[n,])
}
dim(counts)
clus <- maptpx::topics(counts, K=3, tol=0.01);
plot(clus$theta[,1])
plot(clus$theta[,1], type="l", col="red")
plot(clus$theta[,2], type="l", col="red")
plot(clus$theta[,3], type="l", col="red")
counts <- matrix(0, dim(prob_mat)[1], dim(prob_mat)[2])
for(n in 1:dim(omega)[1]){
counts[n,] <-  rmultinom(1, size=5000, prob=prob_mat[n,])
}
##########  apply grade of membership models  ################
clus <- maptpx::topics(counts, K=3, tol=0.01);
plot(clus$theta[,1], type="l", col="red")
plot(clus$theta[,2], type="l", col="red")
plot(clus$theta[,3], type="l", col="red")
cluster1 <- c(rep(0.00001, 300), rep(0.002, 200), rep(0.00001, 300))
sum(cluster1)
cluster1 <- c(rep(0.00001, 300), rep((1-0.00002)/200, 200), rep(0.00001, 300))
sum(cluster1)
cluster1 <- c(rep(0.00001, 300), rep((1-0.006)/200, 200), rep(0.00001, 300))
sum(cluster1)
cluster1 <- c(rep(0.00001, 300), rep((1-0.006)/200, 200), rep(0.00001, 300))
cluster2 <- c(rep(0.00001, 500), rep((1-0.006)/200, 200), rep(0.00001, 100))
cluster3 <- c(rep(0.00001, 100), rep((1-0.006)/200, 200), rep(0.00001, 500))
plot(cluster1, type="l")
plot(cluster2, type="l")
plot(cluster3, type="l")
cluster_theta <- cbind(cluster1, cluster2, cluster3);
omega <- cbind(seq(0,0.4, length.out=100), seq(0.5, 0.2, length.out=100),
1 - seq(0,0.4, length.out=100) - seq(0.5, 0.2, length.out=100))
prob_mat <- omega%*%t(cluster_theta)
counts <- matrix(0, dim(prob_mat)[1], dim(prob_mat)[2])
for(n in 1:dim(omega)[1]){
counts[n,] <-  rmultinom(1, size=5000, prob=prob_mat[n,])
}
clus <- maptpx::topics(counts, K=3, tol=0.01);
plot(clus$theta[,1], type="l", col="red")
plot(clus$theta[,2], type="l", col="red")
plot(clus$theta[,3], type="l", col="red")
plot(cluster1, type="l")
plot(cluster2, type="l")
plot(cluster3, type="l")
clus <- maptpx::topics(counts, K=3, tol=0.01);
plot(clus$theta[,1], type="l", col="red")
plot(clus$theta[,2], type="l", col="red")
plot(clus$theta[,3], type="l", col="red")
clus$BF
clus
clus <- maptpx::topics(counts, K=3, tol=0.01);
clus$BF
clus
plot(clus$theta[,1], type="l", col="red")
plot(clus$theta[,2], type="l", col="red")
plot(clus$theta[,3], type="l", col="red")
omega <- cbind(seq(0,0.4, length.out=100), seq(0.9, 0.1, length.out=100),
1 - seq(0,0.4, length.out=100) - seq(0.9, 0.1, length.out=100))
prob_mat <- omega%*%t(cluster_theta)
counts <- matrix(0, dim(prob_mat)[1], dim(prob_mat)[2])
for(n in 1:dim(omega)[1]){
counts[n,] <-  rmultinom(1, size=5000, prob=prob_mat[n,])
}
##########  apply grade of membership models  ################
clus <- maptpx::topics(counts, K=3, tol=0.01);
clus$BF
plot(clus$theta[,1], type="l", col="red")
plot(clus$theta[,2], type="l", col="red")
plot(clus$theta[,3], type="l", col="red")
plot(clus$theta[,2], type="l", col="red")
plot(clus$theta[,1], type="l", col="red")
plot(clus$theta[,1], type="l", col="red")
line(cluster1, type="l", col="blue")
line(cluster1, col="blue")
lines(cluster1, col="blue")
plot(clus$theta[,1], type="l", col="red")
lines(cluster2, col="blue")
plot(clus$theta[,2], type="l", col="red")
lines(cluster1, col="blue")
plot(clus$theta[,3], type="l", col="red")
lines(cluster3, col="blue")
omega <- cbind(seq(0,0.8, length.out=100), seq(0.9, 0.1, length.out=100),
1 - seq(0,0.8, length.out=100) - seq(0.9, 0.1, length.out=100))
prob_mat <- omega%*%t(cluster_theta)
counts <- matrix(0, dim(prob_mat)[1], dim(prob_mat)[2])
for(n in 1:dim(omega)[1]){
counts[n,] <-  rmultinom(1, size=5000, prob=prob_mat[n,])
}
##########  apply grade of membership models  ################
clus <- maptpx::topics(counts, K=3, tol=0.01);
clus$BF
plot(clus$theta[,1], type="l", col="red")
lines(cluster2, col="blue")
plot(clus$theta[,2], type="l", col="red")
lines(cluster1, col="blue")
plot(clus$theta[,3], type="l", col="red")
lines(cluster1, col="blue")
library(smashtpx)
topic_clus <- smash.topics(counts,
K=3, tol = 100,
smash_gap=2,
smash_method = "gaussian",
init.method = "taddy")
install_github("kkdey/smashtpx")
library(devtools)
install_github("kkdey/smashtpx")
library(smashtpx)
topic_clus <- smash.topics(counts,
K=3, tol = 100,
smash_gap=2,
smash_method = "gaussian",
init.method = "taddy")
remove.packages("slam")
install_github("kkdey/smashtpx")
install_github("kkdey/smashtpx", force=TRUE)
library(devtools)
library(smashtpx)
library(slam)
x <- c(23, 23, 45)
background <- c(0.4, 0.2, 0.4)
chisq.test(as.table(x, round(sum(x) * background)))$p.value
rm(list=ls())
x <- c(2, 0, 1)
chisq.test(as.table(x, round(sum(x) * background)))$p.value
install.packages(c('repr', 'IRdisplay', 'crayon', 'pbdZMQ', 'devtools'))
devtools::install_github('IRkernel/IRkernel')
IRkernel::installspec()
IRkernel::installspec(name = 'ir33', displayname = 'R 3.3')
devtools::install_github("kkdey/aRchaic")
damageLogo_pos
library(aRchaic)
damageLogo_pos
setwd("~/Documents/ancient-damage/R")
out <- get(load("../processed_data/maptpx-runs/lindo2016-maptpx-independent-K-3.rda"))
damageLogo_pos(out$theta, ic.scale = TRUE, renyi_alpha = 10)
source('~/Documents/aRchaic/R/damageLogo_pos.R')
damageLogo_pos(out$theta, ic.scale = TRUE, renyi_alpha = 10)
library(grid)
library(gridBase)
damageLogo_pos(out$theta, ic.scale = TRUE, renyi_alpha = 10)
source('~/Documents/aRchaic/R/damageLogo_pos.R')
damageLogo_pos(out$theta, ic.scale = TRUE, renyi_alpha = 10)
source('~/Documents/aRchaic/R/damageLogo_pos.R')
damageLogo_pos(out$theta, ic.scale = TRUE, renyi_alpha = 10)
source('~/Documents/aRchaic/R/damageLogo_pos.R')
damageLogo_pos(out$theta, ic.scale = TRUE, renyi_alpha = 10)
source('~/Documents/aRchaic/R/damageLogo_pos.R')
damageLogo_pos(out$theta, ic.scale = TRUE, renyi_alpha = 10)
source('~/Documents/aRchaic/R/damageLogo_pos.R')
damageLogo_pos(out$theta, ic.scale = TRUE, renyi_alpha = 10)
source('~/Documents/aRchaic/R/damageLogo_pos.R')
damageLogo_pos(out$theta, ic.scale = TRUE, renyi_alpha = 10)
